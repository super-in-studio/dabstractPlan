<p>&nbsp;</p><p>&nbsp;</p><p><br></p><h1>1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kubernetes 概述</h1><h2>1.1 背景</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kubernetes(以下简称k8s)是google基于Blog进行改进后，开源出来的一款“容器管理应用”。由于近几年来容器技术的火爆，许许多多的服务都不会直接部署在linux主机或各大云厂商的虚拟机上；利用Docker，将每个服务做成一个Image，把他们跑在各自的Container中。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样做的好处有非常多，比如环境配置隔离、服务启动快、移植便捷等等。但是使用的Container多到一定程度，就会带来容器管理上的问题：使用docker ps命令之后有一大堆Container，如果标识的不清楚也很容易混淆；某些分布式服务，需要将Docker部署到许多不同的机器上，这也会增加我们运维的难度。因此，我们现在需要一款“专门管理容器”的平台，为我们提供可视化界面，方便我们对各个容器进行管理。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;k8s就是这样一款辅助我们管理容器的平台，支持管理在分布式环境(即多台服务器上)启动的Container。</p><p><br></p><h2>1.2 &nbsp;基础概念</h2><ul><li>Maste<strong>r</strong></li></ul><p><span style="background-color: rgb(254, 254, 242);">Cluster的大脑，主要职责是调度，可以运行多个master来保证高可用。</span></p><p><br></p><ul><li><strong>Node</strong>：</li></ul><p><span style="background-color: rgb(254, 254, 242);">职责是运行容器应用，Node由Master管理，负责监控并汇报容器的状态，同时根据Master的要求管理容器的生命周期。</span></p><p><br></p><ul><li>Pod</li></ul><p>Pod 是K8s的最小工作单元。每个Pod包含一个或多个容器。</p><p>Ø&nbsp;有些容器天生就是需要紧密联系，一起工作。Pod提供了比容器更高层次的抽象，K8s以Pod为最小单位进行调度、扩展、共享资源、管理生命周期。</p><p>Ø&nbsp;Pod中的所有容器使用同一个网络的namespace，即相同的IP地址和Port空间。它们可以直接用localhost通信。同样的，这些容器可以共享存储，当K8s挂载Volume到Pod上，本质上是将volume挂载到Pod中的每一个容器。</p><p><br></p><ul><li>Pod控制器</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;K8s通常不直接创建Pod，而是通过Controller来管理Pod。Controller中定义了pod的部署属性，比如几个副本、在什么样的Node上运行等。</p><p>K8s提供了多种Controller，包括Deployment、ReplicaSet、DaemonSet、StatefuleSet、Job等。</p><p>Ø&nbsp;<strong>ReplicationController</strong> （副本控制器），确保Pod的数量始终保持设定的个数。也支持Pod的滚动更新。</p><p>Ø&nbsp;<strong>ReplicaSet</strong> （副本集），它不直接使用，有一个声明式更新的控制器叫<strong>Deployment</strong>来负责管理。但是Deployment只能负责管理那些无状态的应用。</p><p>Ø&nbsp;<strong>StatefulSet</strong> （有状态副本集），负责管理有状态的应用。</p><p>Ø&nbsp;<strong>DaemonSet</strong> ，如果需要在每一个Node上只运行一个副本，而不是随意运行，就需要DaemonSet。</p><p>Ø&nbsp;<strong>Job</strong>，运行作业，对于时间不固定的操作，比如：某个应用生成了一大堆数据集，现在需要临时启动一个Pod去清理这些数据集，清理完成后，这个Pod就可以结束了。 这些不需要一直处于运行状态的应用，就用Job这个类型的控制器去控制。如果Pod运行过程中意外中止了，Job负责重启Pod。如果Pod任务执行完了，就不需要再启动了。</p><p>Ø&nbsp;<strong>Cronjob</strong>，周期性作业。</p><p><br></p><ul><li><span style="color: windowtext;">Service：</span></li></ul><p>Deployement可以部署多个副本，每个Pod都有自己的副IP，外界如何访问这些副本。Pod会被频繁的销毁和重启，IP实时变化，不能用IP， 答案是通过service。K8s service 定义了外界访问一组特定Pod的方式。service有自己的IP和端口，service为Pod提供了负载均衡。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: red;">&nbsp;</span></p><p><br></p><ul><li><span style="color: windowtext;">Namespace:&nbsp;</span></li></ul><p>Namespace将物理的Cluster逻辑上划分成多个虚拟Cluster，每个Cluster就是一个Namespace。不同的Namespace里的资源是完全隔离的。</p><p>Ø&nbsp;default：默认的namespace</p><p>Ø&nbsp;kube-system:&nbsp;K8s自己创建的的系统资源放到这个namespace</p><p><br></p><h2>1.3 K8S的架构</h2><p>Kubernetes集群包含有节点代理Kubelet 和Master组件（APIs，scheduler，etc.），下面是K8S的架构图。                    </p><p>Master节点包含API Server、Scheduler（调度器）、ControllerManager（控制器管理器）这三个核心的组件。</p><p>Node节点包含的核心组件有Kubelet、Docker容器引擎、Kube-proxy</p><p><br></p><ul><li><strong>API Server（kube-apiserver）</strong></li></ul><p>提供了HTTP/HTTPS RESTful API,即Kubernetes API。 API server是Kubernetes Cluster的前端接口。其他客户端工具（CLI或UI）以及K8S其它组件可以通过它管理Cluster资源。</p><p><br></p><ul><li><strong>Scheduler</strong><span style="background-color: rgb(254, 254, 242);">(kube-scheduler)</span></li></ul><p>调度器，它<span style="background-color: rgb(254, 254, 242);">负责决定将Pod放在哪个Node上运行。调度时候考虑Cluster拓扑，各个节点的负载，以及应用对高可用、性能、数据亲和性的需求</span>。</p><p><br></p><ul><li><strong>Controller-Manager</strong></li></ul><p>负责监控每一个Controller（控制器）的健康状态，并确保控制器是健康的。而控制器是确保Pod健康的组件。</p><p><br></p><ul><li><strong>etcd</strong></li></ul><p>负责保存K8s Cluster的配置信息和各种资源的状态信息。当数据发生变化时，etcd可以快速的通知K8s 组件。</p><p><br></p><ul><li><strong>Pod网络</strong></li></ul><p>Pod能通信，k8s cluster必须部署Pod网络（比如flannel是其中一个方案）　&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p>&nbsp;</p><p><br></p><ul><li><strong>Kubelet</strong></li></ul><p><span style="background-color: rgb(254, 254, 242);">是Node的agent,当scheduler确定在某个Node上运行Pod后，会将Pod的具体配置信息（image、volume等）发送给该节点的kubelet，kubelet根据这些信息创建和运行容器，并向Master报告运行状态。</span></p><p><br></p><ul><li><strong>Kube-proxy</strong></li></ul><p><span style="background-color: rgb(254, 254, 242);">service在逻辑上代表了后端的多个Pod，外界通过service访问Pod。service接收到的请求是如何转发到Pod的呢？这就是kube-proxy要完成的工作。每个node都运行kube-proxy服务，它负责将访问service的TCP/UDP数据流转发到后端容器。如果有多个副本，kube-proxy实现负载均衡。</span></p><p><br></p><h1>2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kubernetes 集群搭建</h1><h2>2.1 环境准备</h2><p>本次教程，使用docker 18.09.9和kubelet-1.16.4，要求centos7.6以上版本</p><p>  </p><p><br></p><h3>2.1.1&nbsp;关闭selinux</h3><p>查看selinux是否关闭</p><p>  </p><p>先设置临时关闭</p><p>  </p><p>永久关闭</p><p>  </p><p><br></p><h3>2.1.2&nbsp;关闭swap</h3><p><strong>k8s要求系统关闭，否则安装过程会报错</strong></p><p><strong>查看系统是否关闭了swap</strong></p><p><strong>  </strong></p><p><strong>&nbsp;</strong></p><p><strong>临时禁用：swapoff -a</strong></p><p><strong>  </strong></p><p><strong>永久禁用：sed -i.bak '/swap/s/^/#/' /etc/fstab ##注释掉swap那一行</strong></p><p><strong>作用就是修改/etc/fstab配置为如下：</strong></p><p><strong>  </strong></p><p><br></p><h3>2.1.3&nbsp;配置ip_forward转发</h3><p>ip_forward 配置文件当前内容为0，表示禁止数据包转发，将其修改为1表示允许</p><p>echo "1" &gt; /proc/sys/net/ipv4/ip_forward </p><p>  </p><p><br></p><h3>2.1.4&nbsp;更新yum源</h3><p>为了一次性配置好下载源，我们一次性修改好centos7软件源，docker源，k8s源</p><p>先清除掉系统自带配置</p><p>  </p><p>下载centos7的源和docker源</p><p>wget -O /etc/yum.repos.d/CentOS-Base.repo&nbsp;http://mirrors.aliyun.com/repo/Centos-7.repo</p><p>wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/repo/epel-7.repo </p><p>wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</p><p>结果如下：</p><p>  </p><p>配置k8s源</p><p>cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</p><p>[kubernetes]</p><p>name=Kubernetes</p><p>baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</p><p>enabled=1</p><p>gpgcheck=0</p><p>EOF</p><p>  </p><p>刷新yum缓存</p><p>  </p><p>&nbsp;</p><p>&nbsp;</p><p><br></p><h3>2.1.5&nbsp;安装docker</h3><p>docker使用版本 18.09.9</p><p>yum install docker-ce-18.09.9 docker-ce-cli-18.09.9 containerd.io -y</p><p>  </p><p>k8s运行要求docker的<span style="background-color: rgb(242, 244, 245); color: rgb(49, 70, 89);">--cgroup-driver=systemd</span></p><p>  </p><p>启动docker并设置开机启动</p><p>systemctl enable docker&nbsp;&amp;&amp;&nbsp;&nbsp;systemctl start docker</p><p>  </p><p><br></p><h3>2.1.6&nbsp;安装k8s组件：</h3><p>yum install -y kubelet-1.16.4 kubeadm-1.16.4 kubectl-1.16.4</p><p>  </p><p>  </p><p>设置开机启动：systemctl enable kubelet &amp;&amp; systemctl start kubelet</p><p>  </p><p>添加kubectl上下文到环境中</p><p>echo "source &lt;(kubectl completion bash)" &gt;&gt; ~/.bash_profile</p><p>source .bash_profile</p><p>在家目录中，配置生效</p><p>  </p><p>&nbsp;</p><p><br></p><h3>2.1.7&nbsp;内核参数修改</h3><p>k8s网络一般使用flannel，该网络需要设置内核参数bridge-nf-call-iptables=1</p><p>添加参数配置文件：</p><p>  </p><p>执行：sysctl -p /etc/sysctl.d/k8s.conf</p><p>  </p><p><br></p><p>至此，环境准备工作完毕</p><p><br></p><h4>2.1.7.1 内核参数修改失败常见问题</h4><p>有些系统执行sysctl -p /etc/sysctl.d/k8s.conf会报异常，一般是因为</p><p>修改这个参数需要系统有br_netfilter模块</p><p><strong>&nbsp;</strong></p><p>使用lsmod |grep br_netfilter命令，查看系统里是否有br_netfilter模块</p><p><strong>  </strong></p><p>&nbsp;</p><p><strong>新增br_netfilter模块:</strong></p><p><span style="color: rgb(85, 85, 85);">  </span></p><p><strong>上述方式重启后无效。需要配置系统启动加载脚本使其永久生效：</strong></p><p>Ø&nbsp;<strong>先加开机启动动作</strong></p><p><strong style="color: rgb(85, 85, 85);">vi /etc/rc.sysinit</strong></p><p><span style="color: rgb(85, 85, 85);">  </span></p><p>Ø&nbsp;<strong>再做加载模块动作</strong></p><p><strong style="color: rgb(85, 85, 85);">vi /etc/sysconfig/modules/br_netfilter.modules</strong></p><p><span style="color: rgb(85, 85, 85);">  </span></p><p>Ø&nbsp;<strong>再增加执行权限</strong></p><p><span style="color: rgb(85, 85, 85);">  </span></p><p><br></p><p><br></p><h2>2.2 Master节点配置</h2><h3>2.2.1&nbsp;Master节点初始化</h3><p>kubeadm init --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.16.4 --pod-network-cidr=10.244.0.0/16</p><p>这一步，如果出现下面错误，则是前面的2.1.6节点内核没有配置</p><p>  </p><p>正常情况，如下：</p><p>  </p><p>  </p><p>出现这一步，恭喜你，已经成功一大半了！</p><p>接下来，我们按它的提示执行操作</p><p>  </p><p><br></p><h3>2.2.2&nbsp;添加flannel的网络</h3><p>按照master的提示，我们接下来应该配置一个pod network。</p><p>但是，因为国内网络不通的原因，此操作无法完成。</p><p>你只能选择peter老师为你定制的下面这个文件来完成</p><p>上传文件到你的系统后，使用下面命令</p><p>kubectl apply -f peter-flannel.yml </p><p>  </p><p>至此，大功告成</p><p><br></p><h3>2.2.3&nbsp;查看集群</h3><p>查看你k8s集群</p><p>  </p><p>&nbsp;</p><p><br></p><h2>2.3 work节点初始化</h2><p><strong>work节点的配置，相对master来说简单许多，只需要规划好节点的名称即可</strong></p><p><strong>&nbsp;</strong></p><p><br></p><h3>2.3.1&nbsp;设置机器名</h3><p>设置一个机器名为work1</p><p>  </p><p>&nbsp;</p><p>&nbsp;</p><p>配置对应的ip</p><p><strong>  </strong></p><p><br></p><h3>2.3.2&nbsp;加入集群</h3><p>在要加入的工作节点机器上，执行master 初始化时提示的join语句，即加到master的管辖内</p><p><strong>  </strong></p><p><strong>回到master节点再次查看集群</strong></p><p><strong>  </strong></p><p><strong>&nbsp;</strong></p><p><br></p><h1>3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;K8S基础操作</h1><h2>3.1 <span style="background-color: rgb(254, 254, 242);">kubectl的命令用法</span></h2><p><span style="background-color: rgb(254, 254, 242);">可以借助</span>kubectl&nbsp;-h命令学习用法，下面介绍常用的一些命令使用：</p><p><br></p><h3>3.1.1&nbsp;kubectl run，创建一个应用程序</h3><p><span style="background-color: rgb(254, 254, 242);">kubectl run nginx-dep --image=nginx:1.7.9 --port=80 --replicas=2 </span></p><p><span style="background-color: rgb(254, 254, 242);">可以先测试：--dry-run</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><span style="background-color: rgb(254, 254, 242);">正式创建：</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><span style="background-color: rgb(254, 254, 242);">查看服务信息：</span></p><p><span style="background-color: rgb(254, 254, 242);">kubectl get pods -o wide &nbsp;&nbsp;</span></p><p><span style="background-color: rgb(254, 254, 242);">#获取pod的信息，-o wide 表示更详细的显示信息</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><span style="background-color: rgb(254, 254, 242);">看到系统里启动了两个pod服务（运行nginx），分别运行在节点node2和node3上</span></p><p><span style="background-color: rgb(254, 254, 242);">测试nginx服务，服务ok</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><br></p><p><br></p><p><br></p><h3>3.1.2&nbsp;<span style="background-color: rgb(254, 254, 242);">探究pod详情：</span></h3><p><span style="background-color: rgb(254, 254, 242);">kubectl describe pod nginx-dep-5779c9d6c9-cwjth</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><span style="background-color: rgb(254, 254, 242);">进入容器查看：</span></p><p><code>格式：</code><code style="color: red;">kubectl exec</code><span style="color: red;">&nbsp;</span><code style="color: red;">-it podName&nbsp;-c&nbsp;containerName -n namespace -- shell comand</code></p><p><span style="background-color: rgb(254, 254, 242);">kubectl exec -it&nbsp;nginx-dep-5779c9d6c9-cwjth -c nginx-dep /bin/bash</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><br></p><h3>3.1.3&nbsp;<span style="background-color: rgb(254, 254, 242);">暴露服务到外网</span></h3><p><span style="background-color: rgb(254, 254, 242);">将pod创建完成后，访问该pod内的服务只能在集群内部通过pod的的地址去访问该服务；当该pod出现故障后，该pod的控制器会重新创建一个包括该服务的pod,此时访问该服务须要获取该服务所在的新的pod的地址ip去访问。</span></p><p><span style="color: rgb(77, 77, 77);">#删除当前的pod:</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><span style="background-color: rgb(254, 254, 242);">如何保持pod的故障恢复，对调用者无影响呢？</span></p><p><span style="background-color: rgb(254, 254, 242);">可以创建一个service，当新的pod的创建完成后，service会通过pod的label连接到该服务，只需通过service即可访问该服务。</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><span style="background-color: rgb(254, 254, 242);">查看svc的label配置</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><span style="background-color: rgb(254, 254, 242);">上述方式，虽然能够通过service访问到pod服务。但在集群外部，是无法访问到的，如在本地windows机器上，想要访问到nginx服务，网络是不通的。我们可以修改service的类型的NodePort。</span></p><p><span style="background-color: rgb(254, 254, 242);">kubectl edit svc nginx-svc</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><span style="background-color: rgb(254, 254, 242);">查看绑定端口</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><span style="color: rgb(77, 77, 77);">在外部可以通过node节点的地址及该端口访问pod内的服务。</span></p><p><span style="color: rgb(77, 77, 77);">  </span></p><p><br></p><p><br></p><h3>3.1.4&nbsp;<span style="background-color: rgb(254, 254, 242);">服务的伸缩</span></h3><p><span style="color: rgb(77, 77, 77);">Pod创建完成后，当服务的访问量过大时，可以对pod的进行扩展让pod中的服务处理更多的请求；当访问量减小时，可以缩减pod数量，以节约资源。 这些操作都可以在线完成，并不会影响现有的服务。</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><span style="background-color: rgb(254, 254, 242);">缩减服务雷同</span></p><p><br></p><p><br></p><h3>3.1.5&nbsp;服务的在线升级与回滚</h3><p><span style="color: rgb(77, 77, 77);">在kubernetes服务中部署完服务后，对服务的升级可以在线完成，升级出问题后，也可以在线完成回滚。、</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><span style="background-color: rgb(254, 254, 242);">可以看到滚动更新的过程：</span></p><p><span style="background-color: rgb(254, 254, 242);">kubectl get pod -w&nbsp;&nbsp;&nbsp;</span><span style="background-color: rgb(254, 254, 242); color: red;">##w参数是watch，持续执行，并观察改变</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><span style="background-color: rgb(254, 254, 242);">再次查看镜像版本</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><span style="background-color: rgb(254, 254, 242);">还可以再回滚回原来的版本：</span></p><p><span style="background-color: rgb(254, 254, 242);">kubectl rollout undo deployment nginx-dep</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><span style="background-color: rgb(254, 254, 242);">查看版本，又回到1.7.9的版本</span></p><p><span style="background-color: rgb(254, 254, 242);">  </span></p><p><br></p><h2>3.2 YAML文件管理资源</h2><p><span style="background-color: rgb(254, 254, 242);">K8s两种创建资源的方式：</span></p><p><span style="background-color: rgb(254, 254, 242);"> （1）用kubectl命令的方式直接创建：比如前面的创建deployment</span></p><p><span style="background-color: rgb(254, 254, 242);"> （2）通过配置文件和kubectl apply创建，</span></p><p>正式的使用，一般采用第二种方式</p><p><br></p><h3>3.2.1&nbsp;资源清单的格式</h3><p>apiVersion: group/apiversion&nbsp;# 不指定定group，默认为croe</p><p>kind:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#资源类别</p><p>metadata：&nbsp;#资源元数据</p><p>&nbsp;&nbsp;name</p><p>&nbsp;&nbsp;namespace&nbsp;#k8s自身的namespace</p><p>&nbsp;&nbsp;lables</p><p>&nbsp;&nbsp;annotations&nbsp;&nbsp;#主要目的是方便用户阅读查找</p><p>spec:期望的状态（disired state）</p><p>status：当前状态，本字段有kubernetes自身维护，用户不能去定义</p><p><span style="color: red;">&nbsp;&nbsp;&nbsp;•缩进表示层级关系</span></p><p><span style="color: red;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;•不支持制表符“tab”缩进，使用空格缩进</span></p><p><span style="color: red;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;•通常开头缩进2 个空格</span></p><p><span style="color: red;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;•字符后缩进1 个空格，如冒号、逗号等</span></p><p><span style="color: red;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;•“---” 表示YAML格式，一个文件的开始</span></p><p><span style="color: red;">&nbsp;&nbsp;&nbsp;•“#”注释</span></p><p><br></p><h3>3.2.2&nbsp;创建deployment</h3><p># vi nginx-deployment.yaml </p><p>apiVersion: apps/v1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# 配置格式的版本&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p>kind: Deployment&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# 创建的资源类型，这里是deployment</p><p>metadata:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# 元数据</p><p>&nbsp;name: nginx-deployment</p><p>&nbsp;namespace: default</p><p>spec:</p><p>&nbsp;replicas: 2</p><p>&nbsp;selector:</p><p>&nbsp;&nbsp;&nbsp;matchLabels:</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;app: nginx</p><p>&nbsp;template:</p><p>&nbsp;&nbsp;&nbsp;metadata:</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;labels:</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;app: nginx</p><p>&nbsp;&nbsp;&nbsp;spec:</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;containers:</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- name: nginx</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;image: nginx:1.7.9</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ports:</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- containerPort: 80</p><p>此文件定义内容，效果与上一节中的命令方式相同。但配置更为详尽</p><p><br></p><pre class="ql-syntax" spellcheck="false">#使用create 子命令以yaml文件的方式启动
kubectl create -f nginx-deployment.yaml &nbsp;
 
</pre><h3>3.2.3&nbsp;扩容伸缩</h3><p>  </p><p>使用kubectl apply生效</p><p>kubectl apply -f nginx-deployment.yaml </p><p>  </p><p>&nbsp;</p><p><br></p><h3>3.2.4&nbsp;获取资源的apiVersion版本及资源配置的帮助</h3><pre class="ql-syntax" spellcheck="false">k8s中， 可以使用kubectl api-versions 获取当前k8s版本上所有的apiVersion版本信息(每个版本可能不同)
</pre><p>  </p><pre class="ql-syntax" spellcheck="false">可以看到出来，不同的资源属于不同的apiVersion版本
</pre><p>你还可以查看资源的配置清单的二级级别的字段</p><p>  </p><p>三级字段</p><p>  </p><p><br></p><h3>3.2.5&nbsp;使用service提供外部访问</h3><p>vim nginx-service.yaml</p><p>apiVersion: v1</p><p>kind: Service</p><p>metadata:</p><p>&nbsp;name: nginx-service</p><p>&nbsp;labels:</p><p>&nbsp;&nbsp;&nbsp;app: nginx</p><p>spec:</p><p>&nbsp;type: NodePort</p><p>&nbsp;ports:</p><p>&nbsp;- port: 80</p><p>&nbsp;&nbsp;&nbsp;targetPort: 80</p><p>&nbsp;selector:</p><p>&nbsp;&nbsp;&nbsp;app: nginx</p><p>创建：kubectl create -f nginx-svc.yaml </p><p>  </p><p>浏览器访问ok</p><p>  </p><p><br></p><h2>3.3 <a href="https://www.cnblogs.com/panwenbin-logs/p/9907847.html" target="_blank" style="color: rgb(7, 93, 179);">Pod控制器(kube-controller-manager)</a></h2><p>kube-controller-manager 是Kubernetes 的大脑， 它通过 apiserver 监控整个集群的状态， 并确保集群处于预期的工作状态。</p><p><br></p><h3>3.3.1&nbsp;ReplicaSets控制器</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;k8s中最初有个Replication Controller ，它保证了在所有时间内，都有特定数量的Pod副本正在运行，如果太多了，Replication Controller就杀死几个，如果太少了，Replication Controller会新建几个，和直接创建的pod不同的是，Replication Controller会替换掉那些删除的或者被终止的pod，不管删除的原因是什么（维护阿，更新啊，Replication Controller都不关心）。基于这个理由，我们建议即使是只创建一个pod，我们也要使用Replication Controller。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Replication Controller 就像一个进程管理器，监管着不同node上的多个pod,而不是单单监控一个node上的pod,Replication Controller 会委派本地容器来启动一些节点上服务（Kubelet ,Docker）。对于服务和用户来说，Replication Controller是通过一种无形的方式来维持着服务的状态</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ReplicaSet是加强版的Replication Controller，其功能只是扩展了Replication Controller的selector，支持基于集合的selector（version <span style="color: blue;">in</span> (v1.<span style="color: purple;">0</span>, v2.<span style="color: purple;">0</span>)或env notin (dev, qa)），K8s中一般我们不再使用Replication Controller。</p><p><br></p><h3>3.3.2&nbsp;Deployment控制器</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Deployment为Pod和Replica Set（下一代Replication Controller）提供声明式更新。意思就是，Replica Set一是在Deployment里使用的。</p><p>你只需要在Deployment中描述你想要的目标状态是什么，Deployment controller就会帮你将Pod和Replica Set的实际状态改变到你的目标状态。你可以定义一个全新的Deployment，也可以创建一个新的替换旧的Deployment。</p><p>&nbsp;</p><p><br></p><p> 典型的用法：</p><p>1.使用Deployment来创建ReplicaSet。ReplicaSet在后台创建pod。检查启动状态，看它是成功还是失败。</p><p>2.然后，通过更新Deployment的PodTemplateSpec字段来声明Pod的新状态。这会创建一个新的ReplicaSet，Deployment会按照控制的速率将pod从旧的ReplicaSet移动到新的ReplicaSet中。</p><p>3.如果当前状态不稳定，回滚到之前的Deployment revision。每次回滚都会更新Deployment的revision。</p><p>4.扩容Deployment以满足更高的负载。</p><p>5.暂停Deployment来应用PodTemplateSpec的多个修复，然后恢复上线。</p><p>6.根据Deployment 的状态判断上线是否hang住了。</p><p>7.清除旧的不必要的ReplicaSet。</p><p>  </p><p>&nbsp;</p><p><br></p><h3>3.3.3&nbsp;DaemonSet</h3><p>DaemonSet保证在每个Node上都运行一个容器副本，常用来部署一些集群的日志、监控或者其他系统管理应用。k8s内部就启用了这个，一般运维监控才用到它。日志收集，系统监控等</p><p>系统程序，比如kube-proxy, kube-dns, glusterd, ceph等都是DaemonSet</p><p><br></p><h3>3.3.4&nbsp;StatefulSet</h3><p>StatefulSet是为了解决有状态服务的问题（对应Deployments和ReplicaSets是为无状态服务而设计），我们后续讲完了K8s存储后，再回头来讲它的使用</p><p><br></p><h3>3.3.5&nbsp;<a href="https://www.cnblogs.com/caibao666/p/11207677.html" target="_blank" style="color: rgb(26, 139, 200);">Job控制器</a></h3><p>Job控制器用于调配pod对象运行一次性任务，容器中的进程在正常运行结束后不会对其进行重启，而是将pod对象置于completed状态。若容器中的进程因错误而终止，则需要依据配置确定重启与否，未运行完成的pod对象因其所在的节点故障而意外终止后会被重新调度。</p><p>job控制器对象有两种：</p><p>Ø&nbsp;单工作队列的串行式job：即以多个一次性的作业方式串行执行多次作业，直至满足期望的次数</p><p>  </p><p>运行后，pod的状态：</p><p>  </p><p>查看pod的运行日志</p><p>  </p><p>&nbsp;</p><p>Ø&nbsp;多工作队列的并行式job：这种方式可以设置工作队列数，即作业数，每个队列仅负责运行一个作业。</p><p>  </p><p>此任务运行后，查看其执行的pod个数</p><p>  </p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p><br></p><h2>3.4 Pod的调度</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在k8s中当定义某个Pod对象时，若没有特定调度规则设定，则k8s本身会调用GenericScheduler通过预选优选算法来为该Pod选择一个最优Node节点，即最终Node节点是谁是不确定的。例如，我们前面经常用一deployment的过程：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比如这个创建:  </p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;查看其中一个pod的事件列表，第一步都是计算调度的assigned决定：</p><p>  </p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但在实际工作中，我们可能需要指向性地将某个Pod定向调度到某个Node中，K8s为我们准备了几种方式来实现这种需求。</p><p><br></p><h3>3.4.1&nbsp;NodeName强制约束</h3><p>我们可以使用NodeName指定，来强制约束pod要在某个node上运行</p><p>  </p><p>运行查验</p><p>  </p><p>实际上，这种node的指定是强制的，是直接取消掉的k8s的调度计算的</p><p>查看pod的事件列表：</p><p>  </p><p>  </p><p><br></p><h3>3.4.2&nbsp;NodeSelector定向调度</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过kubernetes的label-selector机制进行节点选择，由scheduler调度策略MatchNodeSelector进行label匹配，调度pod到目标节点，该匹配规则是强制约束，使用示例如下：</p><p>1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;给目标node打上一些标签，示例如下：</p><p>kubectl label nodes work2 like=north</p><p>其实就是为work2节点加一个属性，key和value值都随意</p><p>  </p><p>删除这个属性，只需要将key紧接一个“-”字符即可</p><p>kubectl label nodes work2 like-</p><p>  </p><p>2.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在pod的定义加上nodeSelector设置（pod的偏向喜好）</p><p>  </p><p>运行这个pod，看它是否能得偿所愿</p><p>  </p><p><br></p><h3>3.4.3&nbsp;NodeAffinity调度</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NodeSelector调度算法比较简单，只是调度pod到某个拥有特定标签的Node上。而现实世界复杂的多，我们需要的是一系列的策略来决定，于是NodeAffinity出场，扩展了策略</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NodeAffinity 亲和性有两种表达方式：</p><p>Ø&nbsp;RequiredDuringSchedulingIgnoredDuringExecution ：必须满足指定的规则才可以调度Pod到Node上，相当于硬限制。</p><p>Ø&nbsp;PreferredDuringSchedulingIgnoredDuringExecution：强调优先满足指定的规则，相当于软限制，并不强求。</p><p>示例：</p><p>  </p><p>运行尝试，查验结果</p><p>  </p><p>PreferredDuringSchedulingIgnoredDuringExecution的用法，依次类推，希望你能举一反三。此外，此使用匹配语法灵活，你完全可以配出一系列实际效果，如pod节点的互斥性等等</p><p><br></p><h2>3.5 K8S的label作用</h2><p>我们在上述的章节中，看到了k8s中一个特殊的存在：label。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这里特别强调一下：</p><p><span style="background-color: rgb(249, 242, 244);">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;标签是一种简单却又功能强大的kubernetes特性，不仅可以组织pod，也可以组织所有其他的kubernetes资源，标签是可以附加到资源的任意键值对，用以选择具有该确切标签的资源，只要标签的key在资源内是唯一的，一个资源便可以拥有多个标签。</span></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;k8s除了使用标签来控制pod的调度之外，还有两个功能，也是使用label来实现的。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.deploy控制器通过label找到对应控制的pods集群</p><p>  </p><p>2.Service通过label，来绑定port到对应的pods集群，从而提供稳定的服务</p><p>  </p><p>&nbsp;</p><p>&nbsp;</p><p><br></p><h2>3.6 Pod的健康检查</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kubernetes会维持Pod的状态及个数，而Pod内容器失败后往往也会导致pod退出，这么看来，K8s在某种程度上已经帮我们保证了容器服务的安全性。但也有很多场景，仅仅这样远远不够，比如某个时候容器服务假死，或者容器服务已经出错但并未退出。这些情况k8s的策略是无能为力的。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;K8S提供了一处机制，来帮助我们来检查容器的健康的程度。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;健康检查（Health Check）用于检测您的应用实例是否正常工作，是保障业务可用性的一种传统机制，一般用于负载均衡下的业务，如果实例的状态不符合预期，将会把该实例“摘除”，不承担业务流量。Kubernetes中的健康检查使用存活性探针（liveness probes）和就绪性探针（readiness probes）来实现，service即为负载均衡，k8s保证 service 后面的 pod 都可用，是k8s中自愈能力的主要手段。</p><p>&nbsp;</p><p>目前支持的探测方式包括：</p><p><span style="color: red;">·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP</span></p><p><span style="color: red;">·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TCP</span></p><p><span style="color: red;">·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Exec命令</span></p><p>我们主要讲一下常见易用的Exec方式和Http方式</p><p><br></p><h3>3.6.1&nbsp;通过exec方式做健康探测</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于Exec探针，Kubernetes则只是在容器内运行命令。 如果命令以退出代码0返回，则容器标记为健康。 否则，它被标记为不健康。 </p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当您不能或不想运行HTTP服务时，此类型的探针则很有用，但是必须是运行可以检查您的应用程序是否健康的命令。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;用法如以下示例：</p><p>  </p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;测试如下：</p><p>创建pod</p><p>  </p><p>查看pod事件</p><p>  </p><p>可以看到，在容器刚启动的60秒内，服务是正常的。此时healthy文件也在容器里。但容器启动后60秒后，healthy文件自动被删除，此时liveness检测无法探测到healthy文件，于是触发K8S机制剔除掉服务，并重建容器。</p><p><br></p><h3>3.6.2&nbsp;通过HTTP方式做健康探测</h3><p>HTTP探针可能是最常见的自定义Liveness探针类型。 即使您的应用程序不是HTTP服务，您也可以在应用程序内创建轻量级HTTP服务以响应Liveness探针。 Kubernetes去访问一个路径，如果它得到的是200或300范围内的HTTP响应，它会将应用程序标记为健康。 否则它被标记为不健康。</p><p>httpGet配置项：</p><p><br></p><ul><li>host：连接的主机名，默认连接到pod的IP。你可能想在http header中设置"Host"而不是使用IP。</li><li>scheme：连接使用的schema，默认HTTP。</li><li>path: 访问的HTTP server的path。</li><li>httpHeaders：自定义请求的header。HTTP运行重复的header。</li><li>port：访问的容器的端口名字或者端口号。端口号必须介于1和65535之间。</li></ul><p>示例：</p><p>  </p><p>运行此pod实例</p><p>  </p><p>查看事件列表</p><p>  </p><p>此时，我们执行命令删除掉容器内的文件，看容器事件</p><p>  </p><p>  </p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><attachment contenteditable="false" data-atts="%5B%5D" data-aid=".atts-d53bfc6e-8fec-47cc-abe8-4ab5c0bc223c"></attachment><p><br></p>